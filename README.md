# AI Video Generation System

An intelligent multi-stage AI video generation pipeline that creates videos from text prompts using LLM-powered storyboarding and state-of-the-art video generation models.

## ğŸ¬ What It Does

1. **Takes a text prompt** like: "A peaceful forest at sunrise, camera panning through trees"
2. **Generates a detailed storyboard** using Claude AI (3-5 cinematic shots)
3. **Creates videos** for each shot using Stable Video Diffusion
4. **Combines them** into a final polished video

## âœ¨ Features

- ğŸ¤– **Intelligent Storyboarding**: Claude breaks down your prompt into professional shot sequences
- ğŸ¥ **Multiple Models**: Support for Replicate, HuggingFace, and local models
- ğŸ–¼ï¸ **Image-to-Video**: Animate your photos with AI
- ğŸ“Š **Real-time Progress**: Track generation progress for each shot
- ğŸ› ï¸ **CLI & Python API**: Use via command-line or programmatically
- ğŸ¨ **Production Ready**: FastAPI backend + React frontend coming in Phase 2-3

## ğŸš€ Quick Start

### 1. Install

```bash
# Install dependencies
pip install -r requirements.txt

# Install FFmpeg
brew install ffmpeg  # macOS
sudo apt install ffmpeg  # Ubuntu
```

### 2. Configure

```bash
# Create .env file
cp .env.example .env

# Edit .env and add your API keys:
# ANTHROPIC_API_KEY=sk-ant-xxx
# REPLICATE_API_TOKEN=r8_xxx
```

Get API keys:
- Anthropic: https://console.anthropic.com/
- Replicate: https://replicate.com/account/api-tokens

### 3. Verify

```bash
python check_readiness.py
```

### 4. Generate!

```bash
python -m video_engine.cli generate "A peaceful forest at sunrise"
```

## ğŸ“– Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Detailed setup and usage guide
- **[README_VIDEO.md](README_VIDEO.md)** - Complete system documentation
- **[COMMANDS.md](COMMANDS.md)** - Command reference
- **[IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md)** - Development status

## ğŸ’¡ Examples

### Text-to-Video
```bash
python -m video_engine.cli generate "Ocean waves at sunset" --output ocean.mp4
```

### Generate Storyboard Only
```bash
python -m video_engine.cli storyboard "Space journey" --output story.json
```

### Image-to-Video
```bash
python -m video_engine.cli generate "Scene comes alive" --reference-image photo.jpg
```

### Programmatic Usage
```python
from video_engine import VideoOrchestrator

orchestrator = VideoOrchestrator()
job = orchestrator.create_job(prompt="Mountain landscape")
job = orchestrator.execute_job(job.id)
print(f"Video: {job.output_video_path}")
```

## ğŸ—ï¸ Architecture

```
User Prompt
    â†“
Claude LLM (Storyboard Generation)
    â†“
Video Models (Shot Generation)
    â†“
FFmpeg (Video Concatenation)
    â†“
Final Video
```

## ğŸ“ Project Structure

```
ai-video/
â”œâ”€â”€ video_engine/          # Core video generation engine
â”‚   â”œâ”€â”€ cli.py            # Command-line interface
â”‚   â”œâ”€â”€ config.py         # Configuration
â”‚   â”œâ”€â”€ core/             # Orchestration
â”‚   â”œâ”€â”€ llm/              # LLM clients
â”‚   â”œâ”€â”€ models/           # Model adapters
â”‚   â”œâ”€â”€ storage/          # Persistence
â”‚   â””â”€â”€ utils/            # Video utilities
â”œâ”€â”€ workspace/            # Generated videos & jobs
â”œâ”€â”€ examples/             # Example scripts
â”œâ”€â”€ tests/                # Test suite
â””â”€â”€ docs/                 # Documentation
```

## âš¡ CLI Commands

```bash
# Generate video
python -m video_engine.cli generate "Your prompt"

# Generate storyboard
python -m video_engine.cli storyboard "Your prompt"

# List models
python -m video_engine.cli list-models

# List jobs
python -m video_engine.cli list-jobs

# Check system
python check_readiness.py
```

## ğŸ¯ Current Status

### âœ… Phase 1: Core Engine (COMPLETE)
- LLM storyboard generation
- Replicate adapter (SVD, SVD-XT)
- Video concatenation
- CLI interface
- Job management
- Progress tracking

### ğŸš§ Phase 2: API Backend (Planned)
- FastAPI REST endpoints
- WebSocket progress streaming
- Background job queue
- File upload handling

### ğŸ“‹ Phase 3: React Frontend (Planned)
- Web UI with real-time updates
- Storyboard editor
- Video player
- Model selection

## ğŸ’° Cost Estimates

Per 3-shot video (~10 seconds):
- Claude API (storyboard): ~$0.02
- Replicate SVD-XT: ~$0.36
- **Total**: ~$0.40 per video

## ğŸ”§ Requirements

- Python 3.10+
- FFmpeg
- Anthropic API key
- Replicate API token

## ğŸ“Š Performance

- Storyboard generation: 5-10 seconds
- Video per shot: 60-90 seconds
- 3-shot video: ~3-4 minutes total
- 5-shot video: ~5-7 minutes total

## ğŸ› Troubleshooting

Run the readiness check:
```bash
python check_readiness.py
```

Common issues:
- Missing API keys â†’ Check `.env` file
- FFmpeg not found â†’ Install FFmpeg
- Dependencies missing â†’ Run `pip install -r requirements.txt`

## ğŸ¤ Contributing

Phase 1 is complete! Next up:
1. Test with real-world prompts
2. Add more model adapters
3. Build FastAPI backend (Phase 2)
4. Create React frontend (Phase 3)

## ğŸ“ License

MIT License

## ğŸ™ Credits

- Built with [Anthropic Claude](https://www.anthropic.com/)
- Video models via [Replicate](https://replicate.com/)
- FFmpeg for video processing

---

**Ready to generate some amazing videos?** ğŸ¥âœ¨

Start here: `python check_readiness.py`
